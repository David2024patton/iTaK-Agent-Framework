<p align="center">
  <img src="https://img.shields.io/badge/iTaK-Agent_Framework-blue?style=for-the-badge&logo=robot" alt="iTaK Agent Framework">
</p>

<h1 align="center">iTaK Agent Framework</h1>

<p align="center">
  <strong>Intelligent Task Automation Kernel</strong><br>
  A powerful multi-agent automation framework with self-healing capabilities and 10-layer architecture.
</p>

<p align="center">
  <a href="#-features">Features</a> â€¢
  <a href="#-quick-start">Quick Start</a> â€¢
  <a href="#-remote-access">Remote Access</a> â€¢
  <a href="#-architecture">Architecture</a> â€¢
  <a href="#-model-catalog">Models</a>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.10%2B-blue?logo=python" alt="Python 3.10+">
  <img src="https://img.shields.io/badge/License-MIT-green" alt="MIT License">
  <img src="https://img.shields.io/badge/Ollama-Supported-orange?logo=ollama" alt="Ollama Ready">
</p>

---

## ğŸš€ What is iTaK?

iTaK (Intelligent Task Automation Kernel) is a **production-ready multi-agent framework** that turns any AI into an autonomous coding assistant with:

- **ğŸ”§ Self-Healing** - Automatically detects and recovers from failures
- **ğŸ§  Persistent Memory** - Remembers past solutions via ChromaDB
- **ğŸ³ Safe Execution** - Runs untrusted code in Docker sandboxes
- **ğŸŒ Remote Access** - Access your local AI from anywhere via VPS or Cloudflare tunnels
- **ğŸ  Local-First** - Optimized for Ollama and local LLMs

---

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| **One-Command Setup** | `npm install` auto-configures Docker, Ollama, and all services |
| **10-Layer Architecture** | Specialized agents for each phase of development |
| **Remote Access** | Access local AI from anywhere via [VPS tunnels](docs/VPS_SETUP.md) or Cloudflare |
| **API Gateway** | FastAPI gateway with Playwright, SearXNG, and ChromaDB |
| **Circuit Breaker** | Prevents cascade failures with automatic recovery |
| **Docker Sandbox** | Execute code safely in isolated containers |
| **LLM Tracer** | Log all interactions for fine-tuning |

---

## ğŸ“¦ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/David2024patton/iTaK-Agent-Framework.git
cd iTaK-Agent-Framework

# One command does everything
npm install
```

**`npm install` automatically:**
- âœ… Detects your OS (Windows/Mac/Linux)
- âœ… Installs Docker Desktop and Ollama (if needed)
- âœ… Starts all containers (Ollama, ChromaDB, Playwright, SearXNG)
- âœ… Pulls the default LLM model (`qwen3-vl:2b`)
- âœ… Generates `.env` with service URLs
- âœ… Launches `itak` CLI

### Using iTaK

After install, just run:

```bash
itak
```

**Main Menu:**
```
[1] ğŸŒ Web App      - HTML/CSS/JS web application
[2] ğŸ Python       - Python script or automation
[3] âš¡ API/Backend  - REST API or backend service
[4] ğŸ¤– AI Agent     - AI agent or workflow
[5] ğŸ“ Custom       - Describe your project freely
[6] ğŸ’¬ Chat         - Interactive coding assistance

[7] âš¡ API Gateway  - Manage tunnels and remote access
```

---

## ğŸŒ Remote Access

Access your local AI services from anywhere - even without a static IP.

### Option 1: Cloudflare Tunnel (Easiest)

No VPS or account needed! From iTaK:

```bash
itak
> /api
# Select [2] Cloudflare Tunnel (Quick)
```

Gets you a public URL like `https://random-name.trycloudflare.com`

### Option 2: VPS + FRP Tunnel (Best for Production)

For permanent remote access with your own domain:

**First-time setup:**

1. **Set up VPS** â†’ [docs/VPS_SETUP.md](docs/VPS_SETUP.md)
2. **Copy your auth token** from `.env` â†’ `FRP_AUTH_TOKEN=xxx`
3. **Configure VPS in iTaK:**
   ```bash
   itak
   > /api
   # Select [4] Configure VPS Connection
   # Enter your VPS IP and auth token
   ```
4. **Start tunnel:**
   ```bash
   # Select [5] Start/Stop FRP Tunnel
   ```

**Auto-reconnect:** Once configured, the FRP tunnel will **automatically start** on every `npm install` or Docker restart. No need to manually start it again!

**Your VPS endpoints:**

| Service | URL |
|---------|-----|
| Ollama LLM | `http://YOUR_VPS_IP:11434` |
| ChromaDB | `http://YOUR_VPS_IP:29800` |
| Playwright | `http://YOUR_VPS_IP:39281` |
| SearXNG | `http://YOUR_VPS_IP:48192` |

---

## ğŸ”Œ Use in Your IDE

Your local Ollama is **OpenAI-compatible**! Use it with any IDE that supports custom OpenAI endpoints.

### Settings for Any IDE

| Setting | Value |
|---------|-------|
| **Base URL** | `http://localhost:11434/v1` |
| **API Key** | `ollama` (any string works) |
| **Model** | `qwen3-vl:2b` |

### VS Code / Cursor / Continue.dev

```json
{
  "openai.baseUrl": "http://localhost:11434/v1",
  "openai.apiKey": "ollama",
  "openai.model": "qwen3-vl:2b"
}
```

### JetBrains AI Assistant

1. Settings â†’ AI Assistant â†’ Custom Provider
2. Enter Base URL: `http://localhost:11434/v1`
3. Model: `qwen3-vl:2b`

### Test with cURL

```bash
curl http://localhost:11434/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"model":"qwen3-vl:2b","messages":[{"role":"user","content":"Hello!"}]}'
```

Works with: **VS Code, Cursor, JetBrains, Neovim, Emacs, Obsidian, and any OpenAI client!**

---

## ğŸ® GPU Acceleration

If you have an NVIDIA GPU, Ollama will **automatically use CUDA** for faster inference. The setup script detects your GPU and confirms acceleration in the `.env` file.

---

## ğŸ—ï¸ Architecture

iTaK uses a **10-layer architecture** where each layer has a specific role:

| Layer | Name | Role |
|:-----:|------|------|
| 1 | **Analyst** | Parse intent, gather requirements |
| 2 | **Recon** | Research, web scraping, data gathering |
| 3 | **Orchestrator** | Plan and delegate work |
| 4 | **Builder** | Write code and content |
| 5 | **Validator** | Test, lint, verify quality |
| 6 | **Sandbox** | Execute code safely in Docker |
| 7 | **Deployer** | Deploy to production |
| 8 | **Librarian** | Manage memory and skills |
| 9 | **Healer** | Monitor, detect failures, auto-recover |
| 10 | **Swarm** | Multi-agent collaboration |

---

## ğŸ“ Project Structure

```
iTaK-Agent-Framework/
â”œâ”€â”€ src/itak/              # Core framework
â”‚   â”œâ”€â”€ cli/               # Command line interface
â”‚   â”‚   â””â”€â”€ api_manager.py # API Gateway manager
â”‚   â”œâ”€â”€ layers/            # 10-layer architecture
â”‚   â”œâ”€â”€ utilities/         # Circuit breaker, helpers
â”‚   â””â”€â”€ security/          # Docker sandbox
â”œâ”€â”€ docker/
â”‚   â””â”€â”€ api-gateway/       # Docker compose for all services
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ VPS_SETUP.md       # Remote access setup guide
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ postinstall.js     # Auto-setup script
â””â”€â”€ README.md
```

---

## ğŸ³ Docker Services

After `npm install`, these containers run under the `api-gateway` project:

| Service | Port | Description |
|---------|------|-------------|
| **Ollama** | 11434 | Local LLM server |
| **ChromaDB** | 29800 | Vector memory database |
| **Playwright** | 39281 | Browser automation |
| **SearXNG** | 48192 | Private search engine |
| **ComfyUI** | 58127 | AI image generation (GPU) |

---

## ğŸ¤– Model Catalog

iTaK includes a curated catalog of **100+ models** across 20 domain categories. Run `itak` and select a project type to get matched with the best model for your task.

**Popular Models:**
- `qwen3-vl:2b` - Default, fast vision + text
- `qwen2.5-coder:7b` - Specialized for coding
- `deepseek-r1:8b` - Deep reasoning

---

## ğŸ¤ Acknowledgments

Built upon [CrewAI](https://github.com/crewAIInc/crewAI) (MIT License).

---

## ğŸ“„ License

MIT License - see [LICENSE](licenses/LICENSE)
